# ðŸš€ shimmytok v0.7.0

**Full llama.cpp Parity** - All tokenizer types supported

## ðŸŽ¯ Highlights

This release completes support for **all tokenizer types** in llama.cpp's `LLAMA_VOCAB_TYPE` enum.

- âœ… **10/10 vocab models validated** against `llama-tokenize`
- ðŸ†• **4 new tokenizer algorithms**: WPM, UGM, RWKV, PLaMo-2
- ðŸ”§ **Bug fixes** for deepseek-llm and UGM preprocessing

## What's New

### New Tokenizers

| Type | Algorithm | Description |
|------|-----------|-------------|
| **WPM** | Word-Piece Model | BERT-style with phantom space + greedy longest match |
| **UGM** | Unigram | Viterbi-style dynamic programming for optimal tokenization |
| **RWKV** | Trie-based | Greedy matching with escape sequence support |
| **PLaMo-2** | Table-driven | Reverse DP with byte fallback |

### Tokenizer Coverage

| Type | Status |
|------|--------|
| SPM (SentencePiece) | âœ… |
| BPE (Byte-Pair Encoding) | âœ… |
| WPM (Word-Piece Model) | âœ… NEW |
| UGM (Unigram) | âœ… NEW |
| RWKV | âœ… NEW |
| PLaMo-2 | âœ… NEW |

### Validated Models

All models produce **exact token match** with `llama-tokenize`:

| Model | Type | Status |
|-------|------|--------|
| bert-bge | WPM | âœ… |
| command-r | BPE | âœ… |
| deepseek-coder | BPE | âœ… |
| deepseek-llm | BPE | âœ… |
| falcon | BPE | âœ… |
| gpt-2 | BPE | âœ… |
| llama-spm | SPM | âœ… |
| qwen2 | BPE | âœ… |
| refact | BPE | âœ… |
| starcoder | BPE | âœ… |

### New API

```rust
// Query pre-tokenization pattern type
tokenizer.pre_type() -> &str
```

### Bug Fixes

- **deepseek-llm**: Regex pattern simplified for Rust regex compatibility (astral Unicode ranges not supported)
- **UGM**: `user_defined_trie` now correctly preprocesses text before Viterbi DP (was built but never used)

### Decoding Improvements

- `clean_spaces` decoding for llama.cpp parity on punctuation/contraction spacing
- `InvalidUtf8` error variant for better decode error handling

## Installation

```toml
[dependencies]
shimmytok = "0.7"
```

## Usage

```rust
use shimmytok::Tokenizer;

let tokenizer = Tokenizer::from_gguf_file("model.gguf")?;

// Works with any supported tokenizer type!
let tokens = tokenizer.encode("Hello world", true)?;
let text = tokenizer.decode(&tokens)?;

// Check what tokenizer type was loaded
println!("Model: {}", tokenizer.model_type());
println!("Pre-tokenizer: {}", tokenizer.pre_type());
```

## Full Changelog

https://github.com/Michael-A-Kuykendall/shimmytok/compare/v0.6.0...v0.7.0

---

**Thank you for using shimmytok!** ðŸ¦€

If this library helps your project, consider [sponsoring](https://github.com/sponsors/Michael-A-Kuykendall).
